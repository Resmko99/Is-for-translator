import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

data_file = "data.txt"
english_sentences = []
russian_sentences = []
with open(data_file, "r", encoding="utf-8") as file:
    for line in file:
        en_sent, ru_sent = line.strip().split("\t")
        english_sentences.append(en_sent)
        russian_sentences.append(ru_sent)

en_tokenizer = Tokenizer()
en_tokenizer.fit_on_texts(english_sentences)
ru_tokenizer = Tokenizer()
ru_tokenizer.fit_on_texts(russian_sentences)

max_len = max(max(len(en_sent.split()), len(ru_sent.split())) for en_sent, ru_sent in zip(english_sentences, russian_sentences))
en_sequences = en_tokenizer.texts_to_sequences(english_sentences)
ru_sequences = ru_tokenizer.texts_to_sequences(russian_sentences)

en_padded_sequences = pad_sequences(en_sequences, maxlen=max_len, padding='post')
ru_padded_sequences = pad_sequences(ru_sequences, maxlen=max_len, padding='post')


input_vocab_size = len(en_tokenizer.word_index) + 1
output_vocab_size = len(ru_tokenizer.word_index) + 1
latent_dim = 256

encoder_inputs = tf.keras.layers.Input(shape=(None,))
encoder_embedding = tf.keras.layers.Embedding(input_vocab_size, latent_dim, mask_zero=True)(encoder_inputs)
encoder_lstm = tf.keras.layers.LSTM(latent_dim, return_state=True)
encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)
encoder_states = [state_h, state_c]

decoder_inputs = tf.keras.layers.Input(shape=(None,))
decoder_embedding = tf.keras.layers.Embedding(output_vocab_size, latent_dim, mask_zero=True)(decoder_inputs)
decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)
decoder_dense = tf.keras.layers.Dense(output_vocab_size, activation='softmax')
decoder_outputs = decoder_dense(decoder_outputs)

model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)

model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')

model.fit([en_padded_sequences, ru_padded_sequences[:,:-1]], ru_padded_sequences[:,1:], epochs=50, batch_size=1)

model.save('translation_model.h5')
